#!/usr/bin/env node

// Script de test pour vÃ©rifier la connectivitÃ© Ollama avec fetch
console.log('ğŸ§ª Test de connectivitÃ© Ollama avec fetch...\n');

// Test 1: VÃ©rifier la connectivitÃ©
console.log('1ï¸âƒ£ Test de connectivitÃ©...');
const testConnection = async () => {
  try {
    const response = await fetch('http://localhost:11434/api/tags', {
      method: 'GET',
      headers: {
        'Content-Type': 'application/json',
      },
    });
    
    if (response.ok) {
      const data = await response.json();
      console.log('âœ… Ollama accessible via fetch');
      console.log(`ğŸ“¦ ModÃ¨les disponibles: ${data.models?.map(m => m.name).join(', ') || 'Aucun'}`);
      return true;
    } else {
      console.log('âŒ Ollama non accessible (status:', response.status, ')');
      return false;
    }
  } catch (error) {
    console.log('âŒ Ollama non accessible:', error.message);
    return false;
  }
};

// Test 2: Test de gÃ©nÃ©ration de rÃ©ponse
console.log('\n2ï¸âƒ£ Test de gÃ©nÃ©ration de rÃ©ponse...');
const testGeneration = async () => {
  try {
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'llama3.2:3b',
        prompt: 'Tu es un assistant IA spÃ©cialisÃ© dans la gestion de projets. RÃ©ponds en franÃ§ais de maniÃ¨re concise et professionnelle.\n\nUtilisateur: Bonjour, comment Ã§a va ?\n\nAssistant:',
        options: {
          temperature: 0.7,
          num_predict: 100
        }
      })
    });

    if (response.ok) {
      const data = await response.json();
      console.log('âœ… GÃ©nÃ©ration de rÃ©ponse rÃ©ussie');
      console.log(`ğŸ¤– RÃ©ponse: "${data.response || 'Pas de contenu'}"`);
      return true;
    } else {
      console.log('âŒ Erreur de gÃ©nÃ©ration (status:', response.status, ')');
      return false;
    }
  } catch (error) {
    console.log('âŒ Erreur de gÃ©nÃ©ration:', error.message);
    return false;
  }
};

// ExÃ©cuter les tests
async function runTests() {
  try {
    const test1 = await testConnection();
    const test2 = await testGeneration();
    
    if (test1 && test2) {
      console.log('\nğŸ‰ Tous les tests sont passÃ©s !');
      console.log('\nğŸ“‹ RÃ©sumÃ©:');
      console.log('â€¢ âœ… Ollama est accessible via fetch');
      console.log('â€¢ âœ… La gÃ©nÃ©ration de rÃ©ponse fonctionne');
      console.log('\nğŸš€ Le service OllamaService devrait maintenant fonctionner dans l\'application !');
      console.log('\nğŸ’¡ VÃ©rifiez maintenant dans le chatbot Discord - le LLM devrait Ãªtre dÃ©tectÃ© !');
    } else {
      console.log('\nâŒ Certains tests ont Ã©chouÃ©');
      console.log('\nğŸ”§ Solutions possibles:');
      console.log('â€¢ VÃ©rifiez qu\'Ollama est dÃ©marrÃ©: ollama serve');
      console.log('â€¢ VÃ©rifiez que le modÃ¨le est installÃ©: ollama list');
      console.log('â€¢ RedÃ©marrez l\'application: npm run dev');
    }
    
  } catch (error) {
    console.log('\nâŒ Erreur lors des tests:', error.message);
  }
}

runTests();
