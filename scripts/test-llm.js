#!/usr/bin/env node

// Script de test pour vÃ©rifier l'intÃ©gration LLM
import http from 'http';

console.log('ğŸ§ª Test de l\'intÃ©gration LLM...\n');

// Test 1: VÃ©rifier qu'Ollama est accessible
console.log('1ï¸âƒ£ Test de connectivitÃ© Ollama...');
const testOllama = () => {
  return new Promise((resolve, reject) => {
    const req = http.get('http://localhost:11434/api/tags', (res) => {
      let data = '';
      res.on('data', chunk => data += chunk);
      res.on('end', () => {
        try {
          const models = JSON.parse(data);
          console.log('âœ… Ollama accessible');
          console.log(`ğŸ“¦ ModÃ¨les disponibles: ${models.models.map(m => m.name).join(', ')}`);
          resolve(models);
        } catch (error) {
          reject(error);
        }
      });
    });
    
    req.on('error', (error) => {
      console.log('âŒ Ollama non accessible:', error.message);
      reject(error);
    });
    
    req.setTimeout(5000, () => {
      console.log('âŒ Timeout - Ollama non accessible');
      reject(new Error('Timeout'));
    });
  });
};

// Test 2: Test de gÃ©nÃ©ration de rÃ©ponse
console.log('\n2ï¸âƒ£ Test de gÃ©nÃ©ration de rÃ©ponse...');
const testGeneration = () => {
  return new Promise((resolve, reject) => {
    const postData = JSON.stringify({
      model: 'llama3.2:3b',
      prompt: 'Bonjour, comment Ã§a va ?',
      stream: false
    });

    const options = {
      hostname: 'localhost',
      port: 11434,
      path: '/api/generate',
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Content-Length': Buffer.byteLength(postData)
      }
    };

    const req = http.request(options, (res) => {
      let data = '';
      res.on('data', chunk => data += chunk);
      res.on('end', () => {
        try {
          const response = JSON.parse(data);
          console.log('âœ… GÃ©nÃ©ration de rÃ©ponse rÃ©ussie');
          console.log(`ğŸ¤– RÃ©ponse: "${response.response}"`);
          resolve(response);
        } catch (error) {
          reject(error);
        }
      });
    });

    req.on('error', (error) => {
      console.log('âŒ Erreur de gÃ©nÃ©ration:', error.message);
      reject(error);
    });

    req.setTimeout(10000, () => {
      console.log('âŒ Timeout - GÃ©nÃ©ration trop lente');
      reject(new Error('Timeout'));
    });

    req.write(postData);
    req.end();
  });
};

// Test 3: Test de l'application SydoFlow
console.log('\n3ï¸âƒ£ Test de l\'application SydoFlow...');
const testApp = () => {
  return new Promise((resolve, reject) => {
    const req = http.get('http://localhost:8080', (res) => {
      if (res.statusCode === 200) {
        console.log('âœ… Application SydoFlow accessible');
        resolve(true);
      } else {
        console.log(`âŒ Application non accessible (status: ${res.statusCode})`);
        reject(new Error(`Status: ${res.statusCode}`));
      }
    });
    
    req.on('error', (error) => {
      console.log('âŒ Application non accessible:', error.message);
      reject(error);
    });
    
    req.setTimeout(5000, () => {
      console.log('âŒ Timeout - Application non accessible');
      reject(new Error('Timeout'));
    });
  });
};

// ExÃ©cuter tous les tests
async function runTests() {
  try {
    await testOllama();
    await testGeneration();
    await testApp();
    
    console.log('\nğŸ‰ Tous les tests sont passÃ©s !');
    console.log('\nğŸ“‹ RÃ©sumÃ©:');
    console.log('â€¢ âœ… Ollama est accessible et fonctionnel');
    console.log('â€¢ âœ… Le modÃ¨le llama3.2:3b rÃ©pond correctement');
    console.log('â€¢ âœ… L\'application SydoFlow est accessible');
    console.log('\nğŸš€ Votre assistant IA avec LLM est prÃªt !');
    console.log('\nğŸ’¡ Testez maintenant dans le chat Discord :');
    console.log('   - "bonjour"');
    console.log('   - "projets"');
    console.log('   - "Ã©quipe"');
    console.log('   - "aide"');
    
  } catch (error) {
    console.log('\nâŒ Certains tests ont Ã©chouÃ©');
    console.log('\nğŸ”§ Solutions possibles:');
    console.log('â€¢ VÃ©rifiez qu\'Ollama est dÃ©marrÃ©: ollama serve');
    console.log('â€¢ VÃ©rifiez que le modÃ¨le est installÃ©: ollama list');
    console.log('â€¢ VÃ©rifiez que l\'app est dÃ©marrÃ©e: npm run dev');
    console.log('\nğŸ“– Consultez OLLAMA_SETUP.md pour plus d\'aide');
  }
}

runTests();
