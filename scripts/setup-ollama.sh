#!/bin/bash

# Script d'installation automatique d'Ollama pour SydoFlow
# Usage: ./scripts/setup-ollama.sh

echo "ğŸ¤– Installation d'Ollama pour SydoFlow"
echo "======================================"

# VÃ©rifier si Ollama est dÃ©jÃ  installÃ©
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama est dÃ©jÃ  installÃ©"
    ollama --version
else
    echo "ğŸ“¦ Installation d'Ollama..."
    
    # DÃ©tecter le systÃ¨me d'exploitation
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        if command -v brew &> /dev/null; then
            echo "ğŸº Installation via Homebrew..."
            brew install ollama
        else
            echo "âŒ Homebrew non trouvÃ©. Veuillez installer Homebrew ou tÃ©lÃ©charger Ollama depuis https://ollama.ai/download"
            exit 1
        fi
    elif [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        echo "ğŸ§ Installation sur Linux..."
        curl -fsSL https://ollama.ai/install.sh | sh
    else
        echo "âŒ SystÃ¨me d'exploitation non supportÃ©. Veuillez installer Ollama manuellement depuis https://ollama.ai/download"
        exit 1
    fi
fi

echo ""
echo "ğŸš€ DÃ©marrage d'Ollama..."

# DÃ©marrer Ollama en arriÃ¨re-plan
ollama serve &
OLLAMA_PID=$!

# Attendre que Ollama soit prÃªt
echo "â³ Attente du dÃ©marrage d'Ollama..."
sleep 5

# VÃ©rifier que Ollama est en cours d'exÃ©cution
if ps -p $OLLAMA_PID > /dev/null; then
    echo "âœ… Ollama dÃ©marrÃ© avec succÃ¨s (PID: $OLLAMA_PID)"
else
    echo "âŒ Erreur lors du dÃ©marrage d'Ollama"
    exit 1
fi

echo ""
echo "ğŸ“¥ TÃ©lÃ©chargement du modÃ¨le recommandÃ©..."

# TÃ©lÃ©charger le modÃ¨le recommandÃ©
ollama pull llama3.2:3b

echo ""
echo "ğŸ” VÃ©rification de l'installation..."

# VÃ©rifier que le modÃ¨le est installÃ©
if ollama list | grep -q "llama3.2:3b"; then
    echo "âœ… ModÃ¨le llama3.2:3b installÃ© avec succÃ¨s"
else
    echo "âŒ Erreur lors de l'installation du modÃ¨le"
    exit 1
fi

echo ""
echo "ğŸ§ª Test du modÃ¨le..."

# Test rapide du modÃ¨le
echo "Test: 'Bonjour, comment Ã§a va ?'" | ollama run llama3.2:3b --verbose=false | head -3

echo ""
echo "ğŸ‰ Installation terminÃ©e avec succÃ¨s !"
echo ""
echo "ğŸ“‹ RÃ©sumÃ© :"
echo "â€¢ Ollama installÃ© et dÃ©marrÃ©"
echo "â€¢ ModÃ¨le llama3.2:3b installÃ©"
echo "â€¢ Service disponible sur http://localhost:11434"
echo ""
echo "ğŸš€ Vous pouvez maintenant dÃ©marrer SydoFlow :"
echo "   npm run dev"
echo ""
echo "ğŸ’¡ L'assistant IA utilisera maintenant le LLM pour enrichir ses rÃ©ponses !"
echo ""
echo "ğŸ›‘ Pour arrÃªter Ollama :"
echo "   kill $OLLAMA_PID"
echo ""
echo "ğŸ“– Pour plus d'informations, consultez OLLAMA_SETUP.md"
